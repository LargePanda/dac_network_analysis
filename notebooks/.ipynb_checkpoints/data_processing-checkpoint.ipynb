{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = \"center\">DAC Network Construction</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Author():\n",
    "    def __init__(self, name, aid):\n",
    "        self.name = name\n",
    "        self.aid = aid\n",
    "        self.nicknames = []\n",
    "        self.paper_ids = []\n",
    "    \n",
    "    def add_paper(self, pid):\n",
    "        if pid not in self.paper_ids:\n",
    "            self.paper_ids.append(pid)\n",
    "            \n",
    "    def add_nickname(self, name):\n",
    "        if name not in self.nicknames:\n",
    "            self.nicknames.append(name)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Paper():\n",
    "    def __init__(self, title, abstract, year, author_names, b_topic, topics, pid, detc, url):\n",
    "        \n",
    "        # Basic info\n",
    "        self.title = title\n",
    "        self.abstract = abstract\n",
    "        self.year = year\n",
    "        self.author_names = author_names\n",
    "        self.broad_topic = b_topic\n",
    "        self.topics = topics\n",
    "        self.pid = pid\n",
    "        self.detc = detc\n",
    "        self.url = url\n",
    "        \n",
    "        # add later\n",
    "        self.author_ids = []\n",
    "        self.citations = []\n",
    "        self.cited_by = []\n",
    "    \n",
    "    def add_author_id(self, aid):\n",
    "        if aid not in self.author_ids:\n",
    "            self.author_ids.append(aid)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Procedure 1. Read papers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = \"../2016_data/DAC_Entire_DataBase_2016.json\"\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    database = json.load(f)\n",
    "\n",
    "stats = {}\n",
    "for p in database:\n",
    "    stats[p['DETC']] = p['Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1668"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "papers = {}\n",
    "for p in database:\n",
    "    year = p['Year']\n",
    "    if p['DETC'] in stats:\n",
    "        year = stats[p['DETC']]\n",
    "    paper = Paper(p['Title'], p['Abstract'], year,p['Authors'], p['Broad_Topic'],\\\n",
    "                  p['Topics'], p['PaperID'],p['DETC'], p['URL'])\n",
    "    papers[paper.pid] = paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2002: 117,\n",
       " 2003: 143,\n",
       " 2004: 115,\n",
       " 2005: 128,\n",
       " 2006: 118,\n",
       " 2007: 125,\n",
       " 2008: 119,\n",
       " 2009: 122,\n",
       " 2010: 112,\n",
       " 2011: 110,\n",
       " 2012: 123,\n",
       " 2013: 114,\n",
       " 2014: 108,\n",
       " 2015: 114}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = {}\n",
    "\n",
    "for p in papers.values():\n",
    "    if p.year in stats:\n",
    "        stats[p.year]+=1\n",
    "    else:\n",
    "        stats[p.year]=1\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure 2. Read authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## add author into the dataset\n",
    "author_names = {}\n",
    "\n",
    "for p in papers.values():\n",
    "    for n in p.author_names:\n",
    "        author_names[n] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assign IDs to each author\n",
    "\n",
    "id = 0\n",
    "for n in author_names.keys():\n",
    "    author_names[n] = str(id)\n",
    "    id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "authors = {}\n",
    "\n",
    "for name in author_names.keys():\n",
    "    authors[author_names[name]] = Author(name, author_names[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_name_to_author_dict(authors):\n",
    "    ret = {}\n",
    "    for author in authors.values():\n",
    "        ret[author.name] = author\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Connection (between author and paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name2author = make_name_to_author_dict(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2528"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name2author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let each author has paper_id list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for paper in papers.values():\n",
    "    for name in paper.author_names:\n",
    "        author = name2author[name]\n",
    "        \n",
    "        author.add_paper(paper.pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let each paper has author_id list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for paper in papers.values():\n",
    "    for name in paper.author_names:\n",
    "        paper.add_author_id(name2author[name].aid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Name Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect similar name pairs\n",
    "\n",
    "Running the following cell will generate lines of similar names. Each line is formatted as \"author_id, name, author_id, name\". For each line, it the two are indeed similar, them copy and paste the line into data/disambiguation.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\tJames Allison\t463\tJames T. Allison\n",
      "5\tDavid J. Gorsich\t1769\tDavid Gorsich\n",
      "8\tQ. Cheng\t609\tHeidi Q. Chen\n",
      "11\tSteve C. Wang\t257\tC. Wang\n",
      "12\tNiclas Stromberg\t220\tNiclas Strömberg\n",
      "12\tNiclas Stromberg\t679\tNiclas Strömberg\n",
      "13\tYu Gu\t18\tP. Gu\n",
      "13\tYu Gu\t934\tJ. Gu\n",
      "13\tYu Gu\t989\tYu Liu\n",
      "13\tYu Gu\t1605\tXu Guo\n",
      "13\tYu Gu\t2400\tY. Fu\n",
      "18\tP. Gu\t97\tC. Yu\n",
      "18\tP. Gu\t934\tJ. Gu\n",
      "18\tP. Gu\t942\tAshwin P. Gurnani\n",
      "18\tP. Gu\t1870\tW. Hu\n",
      "18\tP. Gu\t2400\tY. Fu\n",
      "23\tLe Chen\t503\tJie Chen\n",
      "23\tLe Chen\t691\tKen Chen\n",
      "23\tLe Chen\t1414\tWei Chen\n",
      "23\tLe Chen\t2018\tLi Chen\n",
      "23\tLe Chen\t2291\tWen Chen\n",
      "28\tTucker J. Marion\t837\tTucker Marion\n",
      "32\tJ.-C. Léon\t2456\tJ. C. Léon\n",
      "42\tAshraf Nassef\t1404\tAshraf O. Nassef\n",
      "49\tZhe Zhang\t1560\tJie Zhang\n",
      "52\tJohn Ziegert\t1898\tJohn C. Ziegert\n",
      "53\tShen Lu\t2255\tZhen Hu\n",
      "60\tMian Li\t118\tXiang Li\n",
      "60\tMian Li\t458\tJia Li\n",
      "60\tMian Li\t930\tMeifang Li\n",
      "60\tMian Li\t1313\tYan Li\n",
      "60\tMian Li\t1339\tMing Li\n",
      "530\tMatthew Watkins\t1965\tMatthew Parkinson\n",
      "76\tV. Krishnamurthy\t771\tVivek Krishnamurthy\n",
      "79\tJames L. Mathieson\t2364\tJames J. Mason\n",
      "93\tChao Qi\t1648\tChao Xu\n",
      "93\tChao Qi\t2042\tChao Hu\n",
      "95\tT. R. Langerak\t1038\tThomas R. Langerak\n",
      "96\tSinobu Yoshimura\t317\tShinobu Yoshimura\n",
      "96\tSinobu Yoshimura\t2175\tYu Yoshimura\n",
      "97\tC. Yu\t934\tJ. Gu\n",
      "97\tC. Yu\t1870\tW. Hu\n",
      "97\tC. Yu\t2400\tY. Fu\n",
      "98\tKristina Wärmefjord\t958\tKristina Wärmefjord\n",
      "101\tChun-Yu Lin\t144\tChung-Yi Lin\n",
      "84\tJunfu Zhang\t1689\tJun Zhang\n",
      "118\tXiang Li\t433\tJing Li\n",
      "118\tXiang Li\t813\tYang Li\n",
      "118\tXiang Li\t1339\tMing Li\n",
      "120\tJing Han\t1237\tJing Wang\n",
      "126\tRobert R. Parker\t87\tRobert R. Mayer\n",
      "129\tKemper E. Lewis\t385\tKemper Lewis\n",
      "131\tYang Wang\t1037\tYan Wang\n",
      "131\tYang Wang\t1237\tJing Wang\n",
      "131\tYang Wang\t1411\tYong Wang\n",
      "140\tRichard H. Crawford\t1691\tRichard Crawford\n",
      "148\tSamuel Drake\t664\tSam Drake\n",
      "155\tKai Liu\t387\tNan Liu\n",
      "155\tKai Liu\t1430\tWei Liu\n",
      "155\tKai Liu\t1599\tLi Liu\n",
      "159\tBryony L. Du Pont\t500\tBryony L. DuPont\n",
      "159\tBryony L. Du Pont\t1776\tBryony DuPont\n",
      "164\tC. G. Jensen\t1874\tC. Greg Jensen\n",
      "166\tA. Farhang-Mehr\t696\tAli Farhang-Mehr\n",
      "166\tA. Farhang-Mehr\t2089\tAli Farhang Mehr\n",
      "169\tSundar Krishnamurthy\t235\tAdarsh Krishnamurthy\n",
      "169\tSundar Krishnamurthy\t1022\tSundar Krishnamurty\n",
      "169\tSundar Krishnamurthy\t1170\tAnand Krishnamurthy\n",
      "171\tQ. Z. Yang\t1311\tJ. C. Yang\n",
      "171\tQ. Z. Yang\t1770\tR. J. Yang\n",
      "172\tYing Xiong\t1335\tJing Xiong\n",
      "176\tThomas Stone\t2101\tThomas M. Stone\n",
      "178\tYinghong Peng\t2439\tYonghong Peng\n",
      "179\tFrank W. Liou\t2195\tFrank Liou\n",
      "180\tZhi-Gang Xu\t272\tZhi Gang Xu\n",
      "192\tKang Zhao\t1460\tDong Zhao\n",
      "192\tKang Zhao\t2064\tLiang Zhao\n",
      "202\tKristin L. Wood\t1900\tKristin Wood\n",
      "217\tSara E. Lego\t1713\tSara Lego\n",
      "220\tNiclas Strömberg\t679\tNiclas Strömberg\n",
      "221\tMohamed M. Saada\t324\tMohamed M. Shalaby\n",
      "227\tMohamed El-Morsi\t1750\tMohamed El Morsi\n",
      "235\tAdarsh Krishnamurthy\t1022\tSundar Krishnamurty\n",
      "235\tAdarsh Krishnamurthy\t1170\tAnand Krishnamurthy\n",
      "236\tFeng Zhou\t1865\tHong Zhou\n",
      "236\tFeng Zhou\t2261\tCheng Feng Zhu\n",
      "244\tRobert Bjärnemo\t2154\tRobert Bjärnemo\n",
      "849\tCristina H. Amon\t1918\tCristina Amon\n",
      "247\tAdel Younis\t1817\tAdel A. Younis\n",
      "255\tM. F. Horstemeyer\t195\tMark F. Horstemeyer\n",
      "257\tC. Wang\t554\tH. Wang\n",
      "257\tC. Wang\t1044\tH. Yang\n",
      "257\tC. Wang\t1084\tZ. Wang\n",
      "257\tC. Wang\t1265\tBo Wang\n",
      "257\tC. Wang\t1724\tL. Wang\n",
      "257\tC. Wang\t2273\tLv Wang\n",
      "257\tC. Wang\t2319\tY. Kang\n",
      "258\tPanos Y. Papalambros\t757\tPanos Papalambros\n",
      "258\tPanos Y. Papalambros\t1454\tP. Papalambros\n",
      "259\tYan Fu\t1313\tYan Li\n",
      "259\tYan Fu\t2400\tY. Fu\n",
      "269\tJian Wan\t743\tJin Wen\n",
      "269\tJian Wan\t1237\tJing Wang\n",
      "269\tJian Wan\t1638\tJian Cao\n",
      "289\tDeepak Sharma\t1459\tDeepak Sivaraman\n",
      "293\tCharlie Manion\t460\tCharles A. Manion\n",
      "298\tY. Rong\t477\tG. Hong\n",
      "298\tY. Rong\t2095\tYu Song\n",
      "298\tY. Rong\t2319\tY. Kang\n",
      "298\tY. Rong\t2373\tZ. Dong\n",
      "298\tY. Rong\t2491\tY. Song\n",
      "317\tShinobu Yoshimura\t2175\tYu Yoshimura\n",
      "324\tMohamed M. Shalaby\t1013\tMohammed Shalaby\n",
      "332\tYi Miao\t538\tMi Xiao\n",
      "337\tJun Liu\t387\tNan Liu\n",
      "337\tJun Liu\t856\tJun Shu\n",
      "337\tJun Liu\t989\tYu Liu\n",
      "337\tJun Liu\t1735\tJun Lu\n",
      "2217\tChao Jiang\t2069\tChao Liang\n",
      "348\tNicholas J. Gaul\t2049\tNicholas Gaul\n",
      "353\tR. D. Sriram\t1926\tRam D. Sriram"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import Levenshtein\n",
    "keys = name2author.keys()\n",
    "\n",
    "for i in range(0, len(keys)):\n",
    "    for j in range(i+1, len(keys)):\n",
    "        p1 = name2author[keys[i]]\n",
    "        p2 = name2author[keys[j]]\n",
    "        \n",
    "        first = p1.name\n",
    "        second = p2.name\n",
    "        \n",
    "        pdist = fuzz.partial_ratio(first, second)\n",
    "        dist = Levenshtein.distance(first, second)\n",
    "        lv_ra = Levenshtein.ratio(first, second)\n",
    "        \n",
    "        if pdist >90 or dist <=2 or lv_ra >0.8:\n",
    "            print p1.aid+\"\\t\"+first+\"\\t\"+p2.aid+\"\\t\"+second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for merging name1 and name2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge(id1, id2, authors, papers):\n",
    "    author1 = authors[id1]\n",
    "    author2 = authors[id2]\n",
    "    \n",
    "    # 1. On Author level\n",
    "    \n",
    "    # let 1 has 2's all paper_ids\n",
    "    for pid in author2.paper_ids:\n",
    "        author1.add_paper(pid)\n",
    "    \n",
    "    # make 2's name as 1's nickname\n",
    "    author1.add_nickname(author2.name)\n",
    "    \n",
    "    # 2. On Papers level\n",
    "    # Make author2's papers that contain author2.id now contain author1.id\n",
    "    for pid in author2.paper_ids:\n",
    "        paper = papers[pid]\n",
    "        paper.author_ids = [id1 if x == id2 else x for x in paper.author_ids]\n",
    "    \n",
    "    # remove id2\n",
    "    authors.pop(id2)\n",
    "    \n",
    "    print author1.name, \" AND \", author2.name, \"ARE MERGED!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from disambiguation file\n",
    "\n",
    "Think of these name pairs as edges in graph, we need to find connected components of that graph and each component is referring to a person's name set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G=nx.Graph()\n",
    "disamb_file_path = \"data/disambiguation.txt\"\n",
    "\n",
    "dependency = []\n",
    "with open(disamb_file_path, \"rb\") as f:\n",
    "    for line in f:\n",
    "        segs = line.strip().split(\"\\t\")\n",
    "        id1 = segs[0]\n",
    "        id2 = segs[2]\n",
    "        G.add_edge(int(id1), int(id2))\n",
    "\n",
    "names = [sorted(list(c)) for c in sorted(nx.connected_components(G), key=len, reverse=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name_list in names:\n",
    "    for i in range(0, len(name_list)-1):\n",
    "        idx = len(name_list) - 1 - i\n",
    "        merge(str(name_list[idx-1]), str(name_list[idx]), authors, papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Network Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pairs(input_list):\n",
    "    length = len(input_list)\n",
    "    ret = []\n",
    "    if length == 1:\n",
    "        return [(input_list[0], input_list[0])]\n",
    "    for i in range(0, length-1):\n",
    "        for j in range(i+1, length):\n",
    "            ret.append((input_list[i], input_list[j]))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def papers_by_year(papers, inf, sup):\n",
    "    ret = []\n",
    "    for p in papers.values():\n",
    "        if p.year <= sup and p.year >= inf:\n",
    "            ret.append(p)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_edges(papers_selected):\n",
    "    edge_list = []\n",
    "    for p in papers_selected:\n",
    "        edge_list.extend(make_pairs(p.author_ids))\n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def author_network(papers, inf_year, sup_year):\n",
    "    papers_between = papers_by_year(papers, inf_year, sup_year)\n",
    "    edge_list = make_edges(papers_between)\n",
    "    \n",
    "    G=nx.Graph()\n",
    "    for edge in edge_list:\n",
    "        G.add_edge(edge[0], edge[1])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_author_node(author_list):\n",
    "    node_list = [\"id\\tname\"]\n",
    "    for author in author_list:\n",
    "        node_info = \"\\t\".join([author.aid, author.name])\n",
    "        node_list.append(node_info)\n",
    "    return node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_paper_node(paper_list):\n",
    "    node_list = [\"id\\ttitle\"]\n",
    "    for paper in paper_list:\n",
    "        node_info = \"\\t\".join([paper.pid, paper.title])\n",
    "        node_list.append(node_info)\n",
    "    return node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_to_file(info_list, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        for line in info_list:\n",
    "            f.write(line)\n",
    "            f.write(\"\\n\")\n",
    "    print filename, \"DONE!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Interpreter():\n",
    "    def __init__(self):\n",
    "        self.digit_holder = {}\n",
    "        self.string_holder = {}\n",
    "        \n",
    "    def add(self, key, value):\n",
    "        self.digit_holder[key] = value\n",
    "        self.string_holder[value] = key\n",
    "    \n",
    "    def lookup(self, key):\n",
    "        if type(key) is int:\n",
    "            return self.digit_holder[key]\n",
    "        else:\n",
    "            return self.string_holder[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake_aid = Interpreter()\n",
    "fake_pid = Interpreter()\n",
    "\n",
    "for i in range(0, len(authors.keys())):\n",
    "    aid = authors.keys()[i]\n",
    "    fake_aid.add(i, aid)\n",
    "    \n",
    "for i in range(0, len(papers.keys())):\n",
    "    pid = papers.keys()[i]\n",
    "    fake_pid.add(i, pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pairs(input_list):\n",
    "    length = len(input_list)\n",
    "    ret = []\n",
    "    if length <= 1:\n",
    "        return []\n",
    "    for i in range(0, length-1):\n",
    "        for j in range(i+1, length):\n",
    "            ret.append((input_list[i], input_list[j]))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Author Network Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def author_network(authors, papers, start_year, end_year):\n",
    "    edge_list = []\n",
    "    #edge_list = [\"from\\tto\\tweight\\tpaper\"]\n",
    "    for p in papers.values():\n",
    "        if p.year < start_year or p.year > end_year:\n",
    "            continue\n",
    "        author_ids = p.author_ids\n",
    "        edges = make_pairs(author_ids)\n",
    "        for edge in edges:\n",
    "            # print edge\n",
    "            edge_list.append(\"\\t\".join([edge[0], edge[1], \"10\", p.title]))\n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def author_from_edgelist(edge_list):\n",
    "    author_set = set()\n",
    "    for edge in edge_list:\n",
    "        segs = edge.split(\"\\t\")\n",
    "        author_set.add(segs[0])\n",
    "        author_set.add(segs[1])\n",
    "    return list(author_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network_output(authors, papers, start_year, end_year, edge_file, node_file):\n",
    "    edge_list = author_network(authors, papers, start_year, end_year)\n",
    "    \n",
    "    with open(edge_file, \"wb\") as f:\n",
    "        f.write(\"from\\tto\\tweight\\tpaper\\n\")\n",
    "        for line in edge_list[0:50]:\n",
    "            f.write(line.encode('utf8'))\n",
    "            f.write(\"\\n\")\n",
    "    node_list = author_from_edgelist(edge_list[0:50])\n",
    "    \n",
    "    with open(node_file, \"wb\") as f:\n",
    "        f.write(\"ID\\tName\\tType\\n\")\n",
    "        for au in node_list[0:50]:\n",
    "            line = \"\\t\".join([au, authors[au].name, \"P\"])\n",
    "            f.write(line.encode('utf8'))\n",
    "            f.write(\"\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network_output(authors, papers, 2011, 2015, \"edges.txt\", \"nodes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Paper Network Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_au = []\n",
    "for au in authors.values():\n",
    "    out_au.append(au.__dict__)\n",
    "\n",
    "with open(\"./Data/Author_Data.json\", \"wb\") as f:\n",
    "    json.dump(out_au, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_pp = []\n",
    "for pp in papers.values():\n",
    "    out_pp.append(pp.__dict__)\n",
    "\n",
    "with open(\"./Data/Paper_Data.json\", \"wb\") as f:\n",
    "    json.dump(out_pp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./Data/Author_Data.pickle\", \"wb\") as f:\n",
    "    pickle.dump(authors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./Data/Paper_Data.pickle\", \"wb\") as f:\n",
    "    pickle.dump(papers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rake\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G=nx.path_graph(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_edgelist(G, \"test.edgelist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o = []\n",
    "for p in papers.values():\n",
    "    o.extend(p.topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
